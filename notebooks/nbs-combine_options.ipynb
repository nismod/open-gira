{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy\n",
    "import pandas\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = Path(\"/home/mert2014/projects/bhutan-demo\")\n",
    "results_dir = Path(\"/home/mert2014/projects/infra-risk-vis/global/etl/raw_data/nbs-adaptation/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input data is available as GPKG files\n",
    "# created by the ETL processing script at\n",
    "# https://github.com/nismod/infra-risk-vis/blob/2cf1dcf6713ba1d71944dd9efb6a68d9bf4d6a29/etl/pipelines/nbs-adaptation/extract-nbs-adaptation-opportunities.ipynb\n",
    "# dataset published at\n",
    "# Harwood, T., & Russell, T. (2025). Global opportunity areas for nature-based solutions to reduce risks to infrastructure [Data set].\n",
    "# Zenodo. https://doi.org/10.5281/zenodo.15001764\n",
    "\n",
    "ls_all = pandas.read_parquet(results_dir / \"landslide_slope_vegetation_with_EAD_grouped.geoparquet\")\n",
    "mg_all = pandas.read_parquet(results_dir / \"mangrove_with_EAD_grouped.geoparquet\")\n",
    "rf_all = pandas.read_parquet(results_dir / \"river_basin_afforestation_with_EAD_grouped.geoparquet\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_all.columns, rf_all.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_all.columns, ls_all.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg_all.columns, mg_all.index.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_options(iso, country_name, mg_all, rf_all, ls_all):\n",
    "    dfs = []\n",
    "    config = [\n",
    "        (mg_all, \"coastal-flooding\", \"mangroves\"),\n",
    "        (rf_all, \"river-flooding\", \"basin_scale_tree_planting\"),\n",
    "        (ls_all, \"landslide\", \"slope_vegetation\"),\n",
    "    ]\n",
    "    for df_all, hazard, planting_type in config:\n",
    "        df = df_all.query(f\"GID_0 == '{iso}'\").drop(columns=\"geometry\").copy()\n",
    "        df[\"country\"] = country_name\n",
    "        df[\"hazard_targeted\"] = hazard\n",
    "        df[\"planting_option\"] = planting_type\n",
    "        df.rename(columns={\n",
    "            colname: colname.replace(\"avoided_ead\", \"baseline_transport_ead_usd\")\n",
    "            for colname in df.columns\n",
    "            if \"avoided_ead\" in colname\n",
    "        }, inplace=True)\n",
    "        # combine landuse (for landslide/slope veg) and shoreline (for coastal flooding/mangrove) categories\n",
    "        df.rename(columns={\n",
    "            \"option_landuse\": \"classes\",\n",
    "            \"option_shoreline\": \"classes\",\n",
    "        }, inplace=True)\n",
    "        df[\"baseline_transport_ead_usd\"] = df[\"baseline_transport_ead_usd_hist_2020_mean\"].copy()\n",
    "        dfs.append(df)\n",
    "\n",
    "    df = pandas.concat(dfs)\n",
    "    df.fillna({\"classes\": \"\"}, inplace=True)\n",
    "\n",
    "    # filter on non-zero expected annual damage\n",
    "    df = df.query(\"baseline_transport_ead_usd > 0.99\").copy()\n",
    "\n",
    "    # add local ID\n",
    "    df[\"opportunity_area_id\"] = numpy.arange(len(df)) + 1\n",
    "\n",
    "    # select columns in order for Excel\n",
    "    # note that we only select the baseline/historical/mean EAD value - there are more scenarios available in the\n",
    "    # data, but the Excel tool expects only a single estimate in its current state\n",
    "    select_columns = [\n",
    "        \"opportunity_area_id\",\n",
    "        \"HYBAS_ID\",\n",
    "        \"GID_0\",\n",
    "        \"country\",\n",
    "        \"GID_1\",\n",
    "        \"area_m2\",\n",
    "        \"area_ha\",\n",
    "        \"planting_cost_usd_per_ha\",\n",
    "        \"regen_cost_usd_per_ha\",\n",
    "        \"carbon_benefit_t_per_ha\",\n",
    "        \"baseline_transport_ead_usd\",\n",
    "        \"biodiversity_benefit\",\n",
    "        \"hazard_targeted\",\n",
    "        \"planting_option\",\n",
    "        \"classes\"\n",
    "    ]\n",
    "    return df[select_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adm_meta = pandas.read_csv(Path().parent / \"boundaries-meta\" / \"gadm36_ne.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_name_lookup = adm_meta.set_index(\"ISO_A3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_name_lookup.loc[\"HKG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_codes = set(ls_all.GID_0.dropna().unique()) | set(mg_all.GID_0.dropna().unique()) | set(rf_all.GID_0.dropna().unique())\n",
    "len(iso_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybas_meta = pandas.read_csv(\"../results/input/hydrobasins/hybas_lev12_v1c_with_gadm_codes_pop.csv\").set_index(\"GID_0\")\n",
    "hybas_meta.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iso in tqdm(iso_codes):\n",
    "    iso_name = iso_name_lookup.loc[iso, \"NAME_LONG\"]\n",
    "    dirname = iso_name_lookup.loc[iso, \"CONTINENT\"]\n",
    "    df = extract_options(iso, iso_name, mg_all, rf_all, ls_all)\n",
    "    (working_dir / \"for_excel\" / dirname).mkdir(exist_ok=True)\n",
    "    df.to_csv(working_dir / \"for_excel\" / dirname / f\"nbs_hydrobasin_options__{iso}.csv\", index=False, float_format=\"%.6g\")\n",
    "\n",
    "    hybas_pop = hybas_meta[hybas_meta.HYBAS_ID.isin(df.HYBAS_ID.unique())]\n",
    "    assert len(hybas_pop) == len(df.HYBAS_ID.unique())\n",
    "    hybas_pop.to_csv(working_dir / \"for_excel\" / dirname / f\"nbs_hydrobasin_population__{iso}.csv\", index=False, float_format=\"%.6g\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regional versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_wb, region_meta in adm_meta[adm_meta.GID_0.isin(iso_codes)].groupby(\"REGION_WB\"):\n",
    "    region_isos = list(region_meta.GID_0.dropna().unique())\n",
    "    region_slug = region_wb.lower().replace(\" \", \"-\").replace(\"&\", \"and\")\n",
    "    dfs = []\n",
    "    for iso in tqdm(region_isos, desc=region_slug):\n",
    "        df = extract_options(iso, mg_all, rf_all, ls_all)\n",
    "        dfs.append(df)\n",
    "    df = pandas.concat(dfs)\n",
    "    df.to_csv(working_dir / \"for_excel\" / f\"wb_region_nbs_hydrobasin_options__{region_slug}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region_wb, region_meta in adm_meta[adm_meta.GID_0.isin(iso_codes)].groupby(\"REGION_WB\"):\n",
    "    region_slug = region_wb.lower().replace(\" \", \"-\").replace(\"&\", \"and\")\n",
    "    df = pandas.read_csv(working_dir / \"for_excel\" / f\"wb_region_nbs_hydrobasin_options__{region_slug}.csv\")\n",
    "    print(f\"{(int(len(df) / 1000))}k {region_slug}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subregion, region_meta in adm_meta[adm_meta.GID_0.isin(iso_codes)].groupby(\"SUBREGION\"):\n",
    "    region_isos = list(region_meta.GID_0.dropna().unique())\n",
    "    region_slug = subregion.lower().replace(\" \", \"-\").replace(\"&\", \"and\")\n",
    "    dfs = []\n",
    "    for iso in tqdm(region_isos, desc=region_slug):\n",
    "        df = extract_options(iso, mg_all, rf_all, ls_all)\n",
    "        dfs.append(df)\n",
    "    df = pandas.concat(dfs)\n",
    "    df.to_csv(working_dir / \"for_excel\" / f\"un_subregion_nbs_hydrobasin_options__{region_slug}.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for subregion, region_meta in adm_meta[adm_meta.GID_0.isin(iso_codes)].groupby(\"SUBREGION\"):\n",
    "    region_slug = subregion.lower().replace(\" \", \"-\").replace(\"&\", \"and\")\n",
    "    df = pandas.read_csv(working_dir / \"for_excel\" / f\"un_subregion_nbs_hydrobasin_options__{region_slug}.csv\")\n",
    "    print(f\"{(int(len(df) / 1000))}k {region_slug}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
