cluster:
  mkdir -p logs/{rule} &&
  sbatch
    --partition={resources.partition}
    --qos={resources.qos}
    --cpus-per-task={threads}
    --mem={resources.mem_mb}
    --job-name=smk-{rule}-{wildcards}
    --output=logs/{rule}/{rule}-{wildcards}-%j.out
    --export=ALL
    --parsable
default-resources:
  - qos=standard  # {basic, standard, priority} only have credits for standard
  - partition=short  # {short, medium, long, devel, interactive}
  - mem_mb=16000
  - time="08:00:00"  # maximum time for a single job
restart-times: 1  # if a job fails, retry it once
max-jobs-per-second: 16  # maximum jobs to _submit_ per second
max-status-checks-per-second: 1
local-cores: 1
latency-wait: 15  # seconds to wait for files to appear before failing
jobs: 64  # max simultaneous jobs
keep-going: True  # do not stop workflow if job(s) fail
rerun-incomplete: True
printshellcmds: True
scheduler: greedy
cluster-status: status-sacct.sh  # script to poll for job status
use-conda: True  # activate conda env prior to running any given rule
# the following path is where an anaconda install (with mamba) is located, envs
# installed here by snakemake or otherwise should be reusable across the group
conda-prefix: /data/ouce-gri-jba/anaconda/envs
# use `mamba` to create envs
# micromamba support coming soon? see:
# https://github.com/snakemake/snakemake/pull/1889
conda-frontend: mamba
